{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Google Gemini API for zero-shot, few-shot, and prompt engineering\n",
        "\n",
        "Zero-shot prompting\n",
        "\n",
        "Few-shot prompting\n",
        "\n",
        "Instruction-style prompting\n",
        "\n",
        "Chain-of-thought prompting\n",
        "\n",
        "Role-based prompting"
      ],
      "metadata": {
        "id": "s8YDcHlySRPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 1. Prerequisites\n"
      ],
      "metadata": {
        "id": "JSWsj4UNSbGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q502uxBaSNCC",
        "outputId": "b3a2aeeb-d334-492a-96a7-7e080929467d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.171.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "pip install google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 2. Setup Gemini API"
      ],
      "metadata": {
        "id": "Fbmz8R1dSgo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# üîë Set your API key (replace with your actual key)\n",
        "genai.configure(api_key=\"AIzaSyCAilRO4OfsQFdPrCtqLz-Qjz5SMKcSPWw\")\n"
      ],
      "metadata": {
        "id": "3U-wmM7nSeti"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 3. Initialize Gemini Model"
      ],
      "metadata": {
        "id": "yQbCKMO5S1Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Gemini model (text-only model)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n"
      ],
      "metadata": {
        "id": "WMYoOLC6Syof"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 4. Zero-shot Prompting"
      ],
      "metadata": {
        "id": "Va0Gc27kS4Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üü° Zero-shot: Ask a question without any examples\n",
        "prompt_zero = \"Translate this sentence into hindi: 'Good morning, how are you?'\"\n",
        "\n",
        "response_zero = model.generate_content(prompt_zero)\n",
        "print(\"üü° Zero-shot Output:\\n\", response_zero.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "E2STcyofS2sv",
        "outputId": "70180b85-26ec-4cd5-9618-bab99d628f91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üü° Zero-shot Output:\n",
            " The most common and natural translation of \"Good morning, how are you?\" in Hindi is:\n",
            "\n",
            "**‡§∏‡•Å‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? (Suprabhaat, aap kaise hain?)**\n",
            "\n",
            "You could also say:\n",
            "\n",
            "* **‡§∂‡•Å‡§≠ ‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? (Shubh Prabhat, aap kaise hain?)**  (Slightly more formal)\n",
            "\n",
            "Both are perfectly acceptable and understood.  The choice depends slightly on context and personal preference.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 5. Few-shot Prompting"
      ],
      "metadata": {
        "id": "yjsPinvDTRlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üü¢ Few-shot: Give a few examples in the prompt\n",
        "prompt_few = \"\"\"\n",
        "Translate these sentences to hinid:\n",
        "1. Hello, how are you? ‚Üí Bonjour, comment √ßa va ?\n",
        "2. What is your name? ‚Üí Comment tu t'appelles ?\n",
        "3. I love programming. ‚Üí\n",
        "\"\"\"\n",
        "\n",
        "response_few = model.generate_content(prompt_few)\n",
        "print(\"\\nüü¢ Few-shot Output:\\n\", response_few.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "ozX6RAZKS6cu",
        "outputId": "bb905d90-b048-4a46-e283-bcadd74dba3f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü¢ Few-shot Output:\n",
            " The question asks for Hindi translations, but provides French examples.  Here are the Hindi translations:\n",
            "\n",
            "1. **Hello, how are you?** ‚Üí ‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç ‡§Ü‡§™? (Namaste, kaise hain aap?)  (Formal) or ‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§ï‡•à‡§∏‡•á ‡§π‡•ã? (Namaste, kaise ho?) (Informal)\n",
            "\n",
            "2. **What is your name?** ‚Üí ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? (Aapka naam kya hai?) (Formal) or ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? (Tumhara naam kya hai?) (Informal)\n",
            "\n",
            "3. **I love programming.** ‚Üí ‡§Æ‡•Å‡§ù‡•á ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó ‡§¨‡§π‡•Å‡§§ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à‡•§ (Mujhe programming bahut pasand hai.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 6. Instruction-style Prompting"
      ],
      "metadata": {
        "id": "HOaal459TV1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üî∑ Instruction-style: Direct command\n",
        "prompt_instruction = \"Summarize the following: 'The Great Wall of China was built to protect Chinese states from invasions. It spans over 13,000 miles.'\"\n",
        "\n",
        "response_instruction = model.generate_content(prompt_instruction)\n",
        "print(\"\\nüî∑ Instruction-style Output:\\n\", response_instruction.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "2reZF53FTT3G",
        "outputId": "400e55ca-9d00-4862-825d-482fffb9a390"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî∑ Instruction-style Output:\n",
            " The Great Wall of China, a structure over 13,000 miles long, was built to defend Chinese states against foreign attacks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 7. Chain-of-Thought Prompting"
      ],
      "metadata": {
        "id": "q92JwVAhTeV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üî∂ Chain-of-Thought: Ask to reason step-by-step\n",
        "prompt_cot = \"Q: A train travels at 60 km/h. How far will it go in 3 hours?\\nA: Let's think step-by-step.\"\n",
        "\n",
        "response_cot = model.generate_content(prompt_cot)\n",
        "print(\"\\nüî∂ Chain-of-Thought Output:\\n\", response_cot.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "HktDC9saTcV-",
        "outputId": "6840b974-1ebc-4109-dfd6-98aac1cf29f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî∂ Chain-of-Thought Output:\n",
            " The train's speed is 60 km/h.  In 1 hour it travels 60 km.  In 3 hours it will travel 3 * 60 km = 180 km.\n",
            "\n",
            "A: 180 km\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 8. Role-based Prompting"
      ],
      "metadata": {
        "id": "XwbjiMvMTkee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üü£ Role-based: Ask model to take a specific persona\n",
        "prompt_role = \"You are an experienced data scientist. Explain overfitting in simple terms.\"\n",
        "\n",
        "response_role = model.generate_content(prompt_role)\n",
        "print(\"\\nüü£ Role-based Output:\\n\", response_role.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "57ojBvNAThKe",
        "outputId": "fa6eedcf-a94c-461c-eb1b-8b0215bda8f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü£ Role-based Output:\n",
            " Imagine you're teaching a dog a trick.  You show it a picture of a cat 100 times, and every time you say \"cat\".  The dog learns to recognize *that specific picture* of a cat really well.  It can identify it perfectly every time!\n",
            "\n",
            "But then you show it a different picture of a cat ‚Äì maybe a different breed, a different angle, a different color ‚Äì and it's confused. It hasn't learned the *general concept* of \"cat\", just that one specific image.\n",
            "\n",
            "That's overfitting.\n",
            "\n",
            "In data science, we build models that learn from data. Overfitting happens when a model learns the *training data* too well, including all its quirks and noise.  It memorizes the specific examples instead of learning the underlying patterns. This means it performs great on the training data (like the dog recognizing its specific cat picture) but poorly on new, unseen data (like failing to recognize other cat pictures).\n",
            "\n",
            "Think of it like this:  a simple model is like a child's drawing of a cat ‚Äì it captures the essence but isn't perfectly detailed. A complex, overfit model is like a hyper-realistic painting of *one* cat ‚Äì incredibly detailed, but useless for recognizing other cats.\n",
            "\n",
            "We want models that generalize well ‚Äì that perform well on both seen and unseen data.  To avoid overfitting, we use techniques like simplifying the model, using more data, or applying regularization (think of it as adding a penalty for being too complex).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üßæ Summary Table\n",
        "\n",
        "| Prompt Type       | Description                        |\n",
        "| ----------------- | ---------------------------------- |\n",
        "| Zero-shot         | No examples, direct question       |\n",
        "| Few-shot          | Few examples to guide model        |\n",
        "| Instruction-style | Straight command (e.g., summarize) |\n",
        "| Chain-of-thought  | Ask model to reason step-by-step   |\n",
        "| Role-based        | Assign the model a role/persona    |\n"
      ],
      "metadata": {
        "id": "IM2ikNmlTowN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGF3a57xTmse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}