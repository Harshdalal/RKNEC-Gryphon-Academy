{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Intermediate Pandas Exercise ---\")\n",
        "print(\"Complete each task by writing the requested Pandas code.\")\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Task 1: Basic Pandas Functions and Converting Arrays to DataFrames\n",
        "print(\"\\n--- Task 1: Basic Pandas Functions and Converting Arrays to DataFrames ---\")\n",
        "# 1.1 Create a Pandas Series named 's1_1' from a list of numbers [10, 20, 30, 40, 50].\n",
        "# 1.2 Create a 3x4 NumPy array named 'np_array1_2' with random integers between 1 and 100.\n",
        "# 1.3 Convert 'np_array1_2' into a Pandas DataFrame named 'df1_3' with columns 'A', 'B', 'C', 'D'.\n",
        "\n",
        "# Your code for Task 1 here:\n",
        "s1_1 = pd.Series([10, 20, 30, 40, 50])\n",
        "np_array1_2 = np.random.randint(1, 101, size=(3, 4))\n",
        "df1_3 = pd.DataFrame(np_array1_2, columns=['A', 'B', 'C', 'D'])\n",
        "\n",
        "print(\"s1_1:\\n\", s1_1)\n",
        "print(\"\\nnp_array1_2:\\n\", np_array1_2)\n",
        "print(\"\\ndf1_3:\\n\", df1_3)\n",
        "\n",
        "\n",
        "# Task 2: Synthetic Data Generation for Practice\n",
        "print(\"\\n--- Task 2: Synthetic Data Generation for Practice ---\")\n",
        "# Create a DataFrame named 'df_sales' with 100 rows and the following columns:\n",
        "# - 'Date': A range of dates from '2023-01-01' to '2023-04-09' (inclusive).\n",
        "# - 'Region': Randomly chosen from ['East', 'West', 'North', 'South'].\n",
        "# - 'Product': Randomly chosen from ['Laptop', 'Mouse', 'Keyboard', 'Monitor'].\n",
        "# - 'Sales': Random integers between 100 and 1000.\n",
        "# - 'Quantity': Random integers between 1 and 10.\n",
        "# - Introduce 5 random NaN values in the 'Sales' column and 3 random NaN values in the 'Quantity' column.\n",
        "\n",
        "# Your code for Task 2 here:\n",
        "num_rows = 100\n",
        "dates = pd.date_range(start='2023-01-01', periods=num_rows, freq='D')[:num_rows] # Ensure exact number of dates\n",
        "regions = np.random.choice(['East', 'West', 'North', 'South'], num_rows)\n",
        "products = np.random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor'], num_rows)\n",
        "sales = np.random.randint(100, 1001, num_rows).astype(float) # Cast to float for NaNs\n",
        "quantity = np.random.randint(1, 11, num_rows).astype(float) # Cast to float for NaNs\n",
        "\n",
        "df_sales = pd.DataFrame({\n",
        "    'Date': dates,\n",
        "    'Region': regions,\n",
        "    'Product': products,\n",
        "    'Sales': sales,\n",
        "    'Quantity': quantity\n",
        "})\n",
        "\n",
        "# Introduce NaN values\n",
        "nan_sales_indices = np.random.choice(df_sales.index, 5, replace=False)\n",
        "nan_quantity_indices = np.random.choice(df_sales.index, 3, replace=False)\n",
        "\n",
        "df_sales.loc[nan_sales_indices, 'Sales'] = np.nan\n",
        "df_sales.loc[nan_quantity_indices, 'Quantity'] = np.nan\n",
        "\n",
        "print(\"df_sales (first 5 rows with potential NaNs):\\n\", df_sales.head())\n",
        "\n",
        "\n",
        "# Task 3: Indexing and Slicing in DataFrames\n",
        "print(\"\\n--- Task 3: Indexing and Slicing in DataFrames ---\")\n",
        "# Use 'df_sales' from Task 2.\n",
        "# 3.1 Select only the 'Region' and 'Sales' columns. Store it in 'df3_1'.\n",
        "# 3.2 Select rows where 'Product' is 'Laptop'. Store it in 'df3_2'.\n",
        "# 3.3 Select rows where 'Region' is 'East' AND 'Sales' are greater than 500. Store it in 'df3_3'.\n",
        "# 3.4 Select the 'Sales' value for the first entry where 'Product' is 'Monitor' (use .loc and .iloc). Store it in 'val3_4'.\n",
        "\n",
        "# Your code for Task 3 here:\n",
        "df3_1 = df_sales[['Region', 'Sales']]\n",
        "df3_2 = df_sales[df_sales['Product'] == 'Laptop']\n",
        "df3_3 = df_sales[(df_sales['Region'] == 'East') & (df_sales['Sales'] > 500)]\n",
        "val3_4 = df_sales.loc[df_sales['Product'] == 'Monitor', 'Sales'].iloc[0] # First 'Monitor' sales value\n",
        "\n",
        "print(\"\\n df3_1 (first 3 rows):\\n\", df3_1.head(3))\n",
        "print(\"\\n df3_2 (first 3 rows):\\n\", df3_2.head(3))\n",
        "print(\"\\n df3_3 (first 3 rows):\\n\", df3_3.head(3))\n",
        "print(\"\\n val3_4 (First 'Monitor' sales value):\", val3_4)\n",
        "\n",
        "\n",
        "# Task 4: Data Cleaning (Handling Missing Values)\n",
        "print(\"\\n--- Task 4: Data Cleaning (Handling Missing Values) ---\")\n",
        "# Use 'df_sales' from Task 2 (which should have NaNs).\n",
        "# 4.1 Check how many missing values are in each column. Store the result in 'missing_counts4_1'.\n",
        "# 4.2 Fill missing 'Sales' values with the mean of the 'Sales' column. Store the modified DataFrame in 'df4_2_filled'.\n",
        "# 4.3 Drop rows that have any missing values in 'df_sales'. Store the result in 'df4_3_dropped'.\n",
        "\n",
        "# Your code for Task 4 here:\n",
        "missing_counts4_1 = df_sales.isnull().sum()\n",
        "df4_2_filled = df_sales.copy() # Work on a copy\n",
        "df4_2_filled['Sales'].fillna(df4_2_filled['Sales'].mean(), inplace=True)\n",
        "df4_3_dropped = df_sales.dropna()\n",
        "\n",
        "print(\"\\nMissing values count:\\n\", missing_counts4_1)\n",
        "print(\"\\ndf_sales after filling Sales NaNs (first 5 rows):\\n\", df4_2_filled.head())\n",
        "print(\"\\ndf_sales after dropping rows with NaNs (first 5 rows):\\n\", df4_3_dropped.head())\n",
        "\n",
        "\n",
        "# Task 5: Data Manipulation (Columns, Sorting, Grouping)\n",
        "print(\"\\n--- Task 5: Data Manipulation (Columns, Sorting, Grouping) ---\")\n",
        "# Use 'df_sales' (the original one with NaNs)\n",
        "# 5.1 Create a new column 'Total_Revenue' which is 'Sales' * 'Quantity'.\n",
        "#     (Be mindful of NaNs, the result should also be NaN where either Sales or Quantity is NaN).\n",
        "# 5.2 Sort 'df_sales' by 'Date' in ascending order, then by 'Sales' in descending order. Store it in 'df5_2_sorted'.\n",
        "# 5.3 Group 'df_sales' by 'Region' and calculate the sum of 'Sales' and 'Quantity' for each region.\n",
        "#     Store the result in 'df5_3_grouped_region'.\n",
        "# 5.4 Group 'df_sales' by 'Product' and find the average 'Sales' for each product.\n",
        "#     Store the result in 'df5_4_grouped_product'.\n",
        "\n",
        "# Your code for Task 5 here:\n",
        "df_sales['Total_Revenue'] = df_sales['Sales'] * df_sales['Quantity']\n",
        "df5_2_sorted = df_sales.sort_values(by=['Date', 'Sales'], ascending=[True, False])\n",
        "df5_3_grouped_region = df_sales.groupby('Region')[['Sales', 'Quantity']].sum()\n",
        "df5_4_grouped_product = df_sales.groupby('Product')['Sales'].mean()\n",
        "\n",
        "print(\"\\ndf_sales with 'Total_Revenue' (first 5 rows):\\n\", df_sales.head())\n",
        "print(\"\\ndf_sales sorted (first 5 rows):\\n\", df5_2_sorted.head())\n",
        "print(\"\\nSales and Quantity by Region:\\n\", df5_3_grouped_region)\n",
        "print(\"\\nAverage Sales by Product:\\n\", df5_4_grouped_product)\n",
        "\n",
        "print(\"\\n--- Exercise Complete! ---\")\n",
        "print(\"Compare your outputs with the expected results to check your understanding.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "NxUpBpNAzYwd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}